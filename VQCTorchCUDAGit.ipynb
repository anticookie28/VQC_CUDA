{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0878ba8d-1c4a-43a8-8b43-71680f86c1aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete! Ready for training.\n",
      "Epoch [1/5], Loss: 0.6005,Train Accuracy: 87.53%\n",
      "Epoch [2/5], Loss: 0.5622,Train Accuracy: 93.94%\n",
      "Epoch [3/5], Loss: 0.5537,Train Accuracy: 94.19%\n",
      "Epoch [4/5], Loss: 0.5498,Train Accuracy: 93.56%\n",
      "Epoch [5/5], Loss: 0.5464,Train Accuracy: 94.03%\n",
      "Test Accuracy: 82.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from PIL import Image\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Operators:\n",
    "    @staticmethod\n",
    "    def PauliX():\n",
    "        return torch.tensor([[0, 1], [1, 0]], dtype=torch.complex64, device=device)\n",
    "\n",
    "    @staticmethod\n",
    "    def PauliY():\n",
    "        return torch.tensor([[0, -1j], [1j, 0]], dtype=torch.complex64, device=device)\n",
    "\n",
    "    @staticmethod\n",
    "    def PauliZ():\n",
    "        return torch.tensor([[1, 0], [0, -1]], dtype=torch.complex64, device=device)\n",
    "\n",
    "    @staticmethod\n",
    "    def Rx(theta):\n",
    "        return torch.cos(theta / 2) * torch.eye(2, dtype=torch.complex64, device=device) - \\\n",
    "               1j * torch.sin(theta / 2) * Operators.PauliX()\n",
    "\n",
    "    @staticmethod\n",
    "    def Ry(theta):\n",
    "        return torch.cos(theta / 2) * torch.eye(2, dtype=torch.complex64, device=device) - \\\n",
    "               1j * torch.sin(theta / 2) * Operators.PauliY()\n",
    "\n",
    "    @staticmethod\n",
    "    def Rz(theta):\n",
    "        return torch.cos(theta / 2) * torch.eye(2, dtype=torch.complex64, device=device) - \\\n",
    "               1j * torch.sin(theta / 2) * Operators.PauliZ()\n",
    "\n",
    "    @staticmethod\n",
    "    def CNOT():\n",
    "        I = torch.eye(2, dtype=torch.complex64, device=device)\n",
    "        zero_proj = torch.tensor([[1, 0], [0, 0]], dtype=torch.complex64, device=device)\n",
    "        one_proj = torch.tensor([[0, 0], [0, 1]], dtype=torch.complex64, device=device)\n",
    "        return torch.kron(zero_proj, I) + torch.kron(one_proj, Operators.PauliX())\n",
    "\n",
    "class utils:\n",
    "    def apply_one_site(site, state, op, L=32):\n",
    "        \"\"\" \n",
    "        Applies a single-site operator to a quantum state in tensorspace.\n",
    "\n",
    "        Args:\n",
    "            site  (int):          The site index on which the operator acts\n",
    "            state (torch.tensor): The state vector of the full system\n",
    "            op    (torch.tensor): A 2x2 operator acting on a single qubit\n",
    "            L     (int):          The total number of sites in the system\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: The resulting state after applying the operator\n",
    "        \n",
    "        \"\"\"\n",
    "        state = state.reshape(2**(site), 2, 2**(L-site-1))\n",
    "        state = torch.tensordot(op, state, dims=([1], [1]))\n",
    "        state = state.permute(1, 0, 2).contiguous()\n",
    "        return state.reshape(-1,)\n",
    "\n",
    "    def apply_two_site(sites, state, op, L=32):\n",
    "        \"\"\"\n",
    "        Applies a (nearest neighbor) two-site operator to a quantum state tensor.\n",
    "\n",
    "        Args:\n",
    "            sites (tuple): A tuple (i, j) indicating the two site indices the operator acts on, where i < j.\n",
    "            state (torch.Tensor): The state vector of the full system (length 2^L).\n",
    "            op (torch.Tensor): A 4x4 operator acting on two qubits.\n",
    "            L (int, optional): The total number of sites in the system. Default is 32.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The resulting state vector after applying the operator at the specified sites.\n",
    "        \"\"\"\n",
    "        state = state.reshape(2**sites[0], 2, 2**(sites[1]-sites[0]-1), 2, 2**(L-sites[1]-1))\n",
    "        op = op.view(2, 2, 2, 2)\n",
    "        state = torch.tensordot(op, state, dims=([2, 3], [1, 3]))\n",
    "        state = state.permute(2, 0, 3, 1, 4).contiguous()\n",
    "        return state.reshape(-1,)\n",
    "\n",
    "    def measure_expectation(state, op, site, L=32):\n",
    "        \"\"\" \n",
    "        Measures the expectation value of a single-site operator on a given quantum state.\n",
    "\n",
    "        Args:\n",
    "            state (torch.Tensor): The state vector of the full system (length 2^L).\n",
    "            op (torch.Tensor): A 2x2 Hermitian operator representing the observable.\n",
    "            site (int): The site at which the measurement is performed.\n",
    "            L (int, optional): The total number of sites in the system. Default is 32.\n",
    "\n",
    "        Returns:\n",
    "            float: The real part of the expectation value of the operator at the specified site.\n",
    "     \n",
    "        \"\"\"\n",
    "        state = state.view(2**(site), 2, 2**(L-site-1))\n",
    "        measured_state = torch.tensordot(op, state, dims=([1], [1]))\n",
    "        expectation_value = torch.vdot(state.view(-1), measured_state.view(-1)).real\n",
    "        return expectation_value\n",
    "\n",
    "def layer(params, state, L=32):\n",
    "    \"\"\" \n",
    "    Definition of a single fully entangling layer of a quantum circuit\n",
    "\n",
    "    Each layer consists of:\n",
    "     - Rotation Ry applied to every qubit with corresponding parameter \n",
    "       (Can be exchanged to every other rotation, always followed by the application)\n",
    "     - A chain of CNOT gates applied between adjacent qubits. \n",
    "\n",
    "    Args:\n",
    "     params (torch.tensor):  a 1D tensor of length L, each (trainable) entry corresponding to a Ry angle\n",
    "     state  (torch.tensor):  The state of the full system\n",
    "     \n",
    "    Returns:\n",
    "     torch.tensor: Quantum state after applying the layer operations\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(L):\n",
    "        Ry_gate = Operators.Ry(params[i])\n",
    "        state = utils.apply_one_site(i, state, Ry_gate, L)\n",
    "    for i in range(L-1):\n",
    "        state = utils.apply_two_site([i, i+1], state, Operators.CNOT(), L)\n",
    "    return state\n",
    "\n",
    "def circuit(params, state, L=32):\n",
    "    n_layers = params.shape[0]\n",
    "    for i in range(n_layers):\n",
    "        state = layer(params[i], state, L=L)\n",
    "    return utils.measure_expectation(state, Operators.PauliZ(), site=7, L=L)\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "from PIL import Image\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "images, labels = mnist.data, mnist.target.astype(int)\n",
    "\n",
    "indices_2 = np.where(labels == 2)[0][:2000]\n",
    "indices_3 = np.where(labels == 3)[0][:2000]\n",
    "selected_indices = np.concatenate((indices_2, indices_3))\n",
    "selected_images = images[selected_indices]\n",
    "selected_labels = labels[selected_indices]\n",
    "\n",
    "selected_labels = np.where(selected_labels == 2, -1, 1)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.reshape(28, 28)\n",
    "    image_resized = Image.fromarray(np.uint8(image))\n",
    "    image_resized = image_resized.resize((16, 16), Image.Resampling.LANCZOS)\n",
    "    image_resized = np.array(image_resized).reshape(-1,)\n",
    "    return image_resized / np.linalg.norm(image_resized)\n",
    "\n",
    "selected_images = np.array([preprocess_image(img) for img in selected_images])\n",
    "\n",
    "X_data = torch.tensor(selected_images, dtype=torch.float32, device=device)\n",
    "Y_data = torch.tensor(selected_labels, dtype=torch.float32, device=device)\n",
    "\n",
    "train_size = int(0.8 * len(X_data))\n",
    "X_train, X_test = X_data[:train_size], X_data[train_size:]\n",
    "Y_train, Y_test = Y_data[:train_size], Y_data[train_size:]\n",
    "\n",
    "batch_size = 50\n",
    "train_loader = torch.utils.data.DataLoader(list(zip(X_train, Y_train)), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(list(zip(X_test, Y_test)), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Data preprocessing complete! Ready for training.\")\n",
    "\n",
    "class QuantumCircuitModel(nn.Module):\n",
    "    def __init__(self, n_layers=32, n_qubits=8):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_qubits = n_qubits\n",
    "        self.params = nn.Parameter(torch.rand(n_layers, n_qubits) * torch.pi*0.01)  \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, input_dim = x.shape  \n",
    "        assert input_dim == 2**self.n_qubits, f\"Expected input_dim={2**self.n_qubits}, but got {input_dim}\"\n",
    "    \n",
    "\n",
    "        state = x.to(dtype=torch.complex64,device=x.device) \n",
    "\n",
    "        results = torch.vmap(lambda s: circuit(self.params, s, L=self.n_qubits))(state)\n",
    "    \n",
    "        return results \n",
    "\n",
    "\n",
    "model = QuantumCircuitModel().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def convert_labels(y):\n",
    "    return (y + 1) / 2  \n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_train, total_train = 0, 0 \n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = convert_labels(labels)  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predictions = torch.sigmoid(outputs) > 0.5\n",
    "        correct_train += (predictions == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_loader):.4f},Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = convert_labels(labels)  \n",
    "\n",
    "        outputs = model(images)\n",
    "        predictions = torch.sigmoid(outputs) > 0.5  \n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e17c37-148b-4ecd-bac9-81353bcdef6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc79ff-2a65-4807-9435-ee89484d97bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01477424-f872-4963-8282-93ff2e024268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb77643-cbe6-42e8-a58c-b911cb44c114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2d790-d42c-49a0-a036-8e8fe7ad41c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2933a-401f-4548-ac89-b7229c9c3e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
